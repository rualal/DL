{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT Text Classification IMDB.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rualal/DL/blob/master/BERT_Text_Classification_IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PI24_yaRFlGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import os\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lpm8TuqGMs1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JA6CzMvQGMwC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"brijesh123\" # username from the json file\n",
        "os.environ['KAGGLE_KEY'] = \"e540038c426b431a7b8f972fba9e4254\" # key from the json file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4pVmcT0t5Oh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9T7eidMYGMym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip imdb-dataset-of-50k-movie-reviews.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hm3lCq7uGM1a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from transformers import (TFBertForSequenceClassification, \n",
        "                          BertTokenizer)\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MvkQrdEbGM91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('IMDB Dataset.csv')\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvcC8y4aGNAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_encoder = preprocessing.LabelEncoder()\n",
        "data['sentiment'] = label_encoder.fit_transform(data['sentiment'])\n",
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VmHH2mVUGNDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = (np.array(data['review']))\n",
        "y = (np.array(data['sentiment']))\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
        "print(\"Train dataset shape: {0}, \\nTest dataset shape: {1}\".format(X_train.shape, X_test.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yg978u_iGNJa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bert_model = TFBertForSequenceClassification.from_pretrained(\"bert-base-cased\")\n",
        "bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-cased\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQfWAE_MTJxk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pad_token=0\n",
        "pad_token_segment_id=0\n",
        "max_length=128\n",
        "\n",
        "def convert_to_input(reviews):\n",
        "  input_ids,attention_masks,token_type_ids=[],[],[]\n",
        "  \n",
        "  for x in tqdm(reviews,position=0, leave=True):\n",
        "    inputs = bert_tokenizer.encode_plus(x,add_special_tokens=True, max_length=max_length)\n",
        "    \n",
        "    i, t = inputs[\"input_ids\"], inputs[\"token_type_ids\"]\n",
        "    m = [1] * len(i)\n",
        "\n",
        "    padding_length = max_length - len(i)\n",
        "\n",
        "    i = i + ([pad_token] * padding_length)\n",
        "    m = m + ([0] * padding_length)\n",
        "    t = t + ([pad_token_segment_id] * padding_length)\n",
        "    \n",
        "    input_ids.append(i)\n",
        "    attention_masks.append(m)\n",
        "    token_type_ids.append(t)\n",
        "  \n",
        "  return [np.asarray(input_ids), \n",
        "            np.asarray(attention_masks), \n",
        "            np.asarray(token_type_ids)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kitY8ZX4mHwe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "bfa8d76f-2c63-4860-b789-7c054a43f6bf"
      },
      "source": [
        "X_test_input=convert_to_input(X_test)\n",
        "X_train_input=convert_to_input(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10000/10000 [00:42<00:00, 237.04it/s]\n",
            "100%|██████████| 40000/40000 [02:47<00:00, 239.28it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2--NOpQk7dMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def example_to_features(input_ids,attention_masks,token_type_ids,y):\n",
        "  return {\"input_ids\": input_ids,\n",
        "          \"attention_mask\": attention_masks,\n",
        "          \"token_type_ids\": token_type_ids},y\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train_input[0],X_train_input[1],X_train_input[2],y_train)).map(example_to_features).shuffle(100).batch(32).repeat(5)\n",
        "\n",
        "\n",
        "test_ds=tf.data.Dataset.from_tensor_slices((X_test_input[0],X_test_input[1],X_test_input[2],y_test)).map(example_to_features).batch(64)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvZVfO_CGNgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
        "\n",
        "bert_model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qu2BiuepGNre",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "28d01ecb-ff88-4b1d-8ae2-ab7eb6c060b9"
      },
      "source": [
        "print(\"Fine-tuning BERT on IMDB\")\n",
        "bert_history = bert_model.fit(train_ds, epochs=3, validation_data=test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fine-tuning BERT on MRPC\n",
            "Train for 6250 steps, validate for 157 steps\n",
            "Epoch 1/3\n",
            " 652/6250 [==>...........................] - ETA: 64:02:30 - loss: 0.3961 - accuracy: 0.8107"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrHEZ0ejZc2-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def example_to_features_predict(inputs):\n",
        "  return {\"input_ids\": inputs[0],\n",
        "          \"attention_mask\": inputs[1],\n",
        "          \"token_type_ids\": inputs[2]}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_c-KnCgAGNwJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "3883aefd-9bb4-4f01-9bda-7f8918f0cec2"
      },
      "source": [
        "X_test[5:8],y_test[5:8]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['On the pure theatrical side, Last Stand was great, as the reenactments and soundtrack are very entertaining, but there are better accounts of this battle found elsewhere that, while not as long or as flashy, are far more historically comprehensive.<br /><br />Certain little details, such as the misuse of the word \"hoplon\" for the Greek hoplite shield and the mispronounciations of various names and words, really ate at me.<br /><br />My guess would be, that because \"Last Stand of the 300\" was aired the eve of the theatrical release of \"300\", the History Channel was only trying to ride the coattails of the movie\\'s hype.<br /><br />If you\\'re looking for a depiction that\\'s historically accurate in all respects possible, you\\'d have better luck elsewhere.',\n",
              "        \"No. I'm not kidding with this one. He was a guest reviewer for Entertainment Weekly and gave this movie positive marks. And who can blame him? This is a charming, upbeat, and rather funny Disney movie. Who doesn't love kittens? The music in Ev'rybody Wants To Be A Cat is jamming. It makes me want to snap my fingers or something. Only years later when Cats Don't Dance came out have I seen a movie that was that musically fun. What Aristocats lacks in animation and story, it makes up for in charm. Plus, everything moves at a relaxed pace, and even the villain isn't all that scary. It's perfect for the younger set while not being so sappy that adults can't like it. If Snoop was here, I'm sure he would say the same thing. Yeah. Dig those CRAZY cats, man.\",\n",
              "        \"The problem with making a movie like this, though, is that the finale, the crème-de-la-creme of the movie, the battle between the two souped-up ships, must be done well. Disappointingly, this scene in Ironclads is obviously done completely with little model ships in an overgrown tub. There's no tension, little explanation of what exactly is going on and what the timeframe is of the stand-off.<br /><br />The film takes quite a few liberties with the surrounding story, as all true stories do when converted to a movie, such as the Union traitor and most notably that of Betty Stuart (Madsen), a Virginia belle.<br /><br />It resorts to making a possibly-decent movie involving an interesting story on the ironclads to preaching about the evils of slavery. It was out of place in this historical drama, and was a cheap ploy to bring in the women viewers. It only succeeded in lessening the positives about the film.\"],\n",
              "       dtype=object), array([0, 1, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pw2Gg2UNGNyx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83bd5dfc-68b5-444b-a135-2f0d5fe1eb4e"
      },
      "source": [
        "X_predict_input=convert_to_input(X_test[1:4])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [00:00<00:00, 108.01it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYAdOVaYGN1P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_ds=tf.data.Dataset.from_tensor_slices(X_predict_input).map(example_to_features_predict).batch(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C8Y0aSYiGNec",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c8df959b-2a19-460c-c34a-278808e968cf"
      },
      "source": [
        "bert_model.predict_on_batch(test_ds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(64, 2), dtype=float32, numpy=\n",
              " array([[ 0.68230027,  0.04853292],\n",
              "        [ 1.5659124 , -1.2430305 ],\n",
              "        [-0.30376363,  0.4779889 ],\n",
              "        [ 1.5845535 , -0.9463671 ],\n",
              "        [ 0.8431733 , -0.42819792],\n",
              "        [ 0.4753108 ,  0.16980031],\n",
              "        [-0.71908486,  0.7445457 ],\n",
              "        [ 0.21682754,  0.24314192],\n",
              "        [-1.0483649 ,  1.0591835 ],\n",
              "        [ 0.8442112 , -0.12866004],\n",
              "        [-0.690723  ,  0.741695  ],\n",
              "        [-0.52187204,  0.5827493 ],\n",
              "        [-0.73065066,  0.6999336 ],\n",
              "        [ 1.5705034 , -1.3012695 ],\n",
              "        [ 0.51423615, -0.05937077],\n",
              "        [ 1.371553  , -1.1206478 ],\n",
              "        [ 1.7374214 , -1.2659613 ],\n",
              "        [-0.65970606,  0.69999844],\n",
              "        [ 0.7414726 , -0.29334533],\n",
              "        [ 1.7821999 , -1.2459989 ],\n",
              "        [-0.9383836 ,  0.8871614 ],\n",
              "        [-0.3621861 ,  0.38542902],\n",
              "        [-1.5017791 ,  1.5198052 ],\n",
              "        [-1.1472266 ,  1.1290525 ],\n",
              "        [-0.78660816,  0.78397816],\n",
              "        [ 1.1351368 , -0.35748467],\n",
              "        [ 0.32434037,  0.10728239],\n",
              "        [ 0.1731317 ,  0.17633751],\n",
              "        [ 0.351748  ,  0.26739052],\n",
              "        [ 1.3363483 , -1.0356576 ],\n",
              "        [ 1.1157267 , -0.34480435],\n",
              "        [ 0.90682644, -0.52694136],\n",
              "        [ 0.6257205 ,  0.05020054],\n",
              "        [ 1.1665257 , -0.49991477],\n",
              "        [-0.9910613 ,  0.9517941 ],\n",
              "        [ 1.6062689 , -1.3040012 ],\n",
              "        [ 1.6604997 , -1.3436078 ],\n",
              "        [ 1.247768  , -0.5234471 ],\n",
              "        [-0.06187208,  0.38614768],\n",
              "        [ 1.2296863 , -0.4614943 ],\n",
              "        [-0.21341132,  0.5374192 ],\n",
              "        [ 1.0102223 , -0.3270543 ],\n",
              "        [-0.4185371 ,  0.5561507 ],\n",
              "        [ 0.8595628 , -0.13863662],\n",
              "        [-0.36214867,  0.5337417 ],\n",
              "        [ 1.5187749 , -1.2854362 ],\n",
              "        [ 0.6568697 , -0.17721358],\n",
              "        [-0.11738934,  0.38589048],\n",
              "        [-0.6300227 ,  0.69363636],\n",
              "        [-0.48907632,  0.5866266 ],\n",
              "        [-1.04819   ,  0.8664696 ],\n",
              "        [ 0.6114693 ,  0.04146379],\n",
              "        [-1.4039797 ,  1.3880512 ],\n",
              "        [-1.0331416 ,  1.0399874 ],\n",
              "        [-0.9665113 ,  0.9294432 ],\n",
              "        [-0.6227476 ,  0.569112  ],\n",
              "        [ 1.047664  , -0.20694596],\n",
              "        [ 1.7268615 , -1.1027015 ],\n",
              "        [ 1.5038131 , -1.3084334 ],\n",
              "        [ 0.21752422,  0.18812704],\n",
              "        [ 1.4041812 , -1.1557065 ],\n",
              "        [-1.5204035 ,  1.5116957 ],\n",
              "        [ 0.22436808,  0.10060297],\n",
              "        [-0.453279  ,  0.6116496 ]], dtype=float32)>,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    }
  ]
}